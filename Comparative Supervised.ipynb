{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN949svMWEuroRlT81y+Ssf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","**Aim:**\n","\n","To perform a comparative analysis of different machine learning algorithms, namely Artificial Neural Networks (ANN), Support Vector Machines (SVM), Naive Bayes, Decision Trees (DT), and k-Nearest Neighbors (KNN), on the Diabetes dataset for the task of classification to determine the most effective algorithm for predicting diabetes occurrences.\n","\n","**Title:**\n","\n","\"Comparative Analysis of Machine Learning Algorithms for Diabetes Prediction: ANN, SVM, Naive Bayes, DT, and KNN\"\n","\n","**Dataset Source:**\n","\n","The Diabetes dataset is sourced from the UCI Machine Learning Repository, containing various features such as glucose concentration, blood pressure, BMI, age, and other health-related metrics. The dataset aims to predict the onset of diabetes within a certain period based on these features.\n","\n","**Theory (Explanation of Algorithms):**\n","\n","**1. Artificial Neural Networks (ANN):**\n","\n","Explanation: ANN is a computational model inspired by the human brain, consisting of interconnected nodes (neurons) organized in layers (input, hidden, output).\n","Functionality: It learns complex patterns by adjusting weights and biases through forward propagation and backpropagation.\n","\n","**2. Support Vector Machines (SVM):**\n","\n","Explanation: SVM is a supervised learning algorithm used for classification and regression tasks.\n","Functionality: SVM finds the optimal hyperplane that best separates classes by maximizing the margin between them.\n","\n","**3. Naive Bayes:**\n","\n","Explanation: Naive Bayes is a probabilistic classifier based on Bayes' theorem with an assumption of independence between features.\n","Functionality: It computes the probability of a data point belonging to a particular class using prior probabilities and likelihoods.\n","\n","**4. Decision Trees (DT):**\n","\n","Explanation: DT is a tree-like structure where internal nodes represent feature splits, and leaf nodes represent class labels.\n","Functionality: It recursively splits data based on features to create a tree, making predictions by traversing from the root to leaf nodes.\n","\n","**5. k-Nearest Neighbors (KNN):**\n","\n","Explanation: KNN is a simple and effective algorithm based on instance-based learning.\n","Functionality: It classifies new data points by assigning them the majority class label among their k-nearest neighbors in the feature space.\n","\n","**Conclusion:**\n","\n","After performing a comprehensive comparative analysis of these algorithms on the Diabetes dataset, several observations can be made:\n","\n","Performance Metrics: Evaluate each algorithm's accuracy, precision, recall, F1-score, and AUC-ROC to determine its classification performance.\n","Algorithm Suitability: Identify which algorithm provides the best balance between predictive accuracy, computational efficiency, and robustness for the given dataset.\n","Consideration of Hyperparameters: Optimize hyperparameters for each algorithm to improve their predictive performance and generalizability."],"metadata":{"id":"OEQZ8PMnBywq"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"eJAS4drlF7rg","executionInfo":{"status":"ok","timestamp":1701347301220,"user_tz":-330,"elapsed":5,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# ANN\n","# Load the 20 newsgroups dataset\n","categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n","newsgroups = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n","\n","# Preprocess text data using TF-IDF vectorization\n","vectorizer = TfidfVectorizer(max_features=1000)\n","X = vectorizer.fit_transform(newsgroups.data)\n","y = newsgroups.target\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Initialize and train the Neural Network (MLPClassifier)\n","mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n","mlp.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = mlp.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Display classification report\n","print(classification_report(y_test, y_pred, target_names=newsgroups.target_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qzm0xLQMV5L","executionInfo":{"status":"ok","timestamp":1701347442657,"user_tz":-330,"elapsed":17362,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}},"outputId":"06eb8899-7bd3-467d-c03e-8c74e714efc3"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9228723404255319\n","                        precision    recall  f1-score   support\n","\n","           alt.atheism       0.95      0.88      0.92       252\n","         comp.graphics       0.92      0.93      0.93       295\n","               sci.med       0.90      0.92      0.91       299\n","soc.religion.christian       0.92      0.95      0.93       282\n","\n","              accuracy                           0.92      1128\n","             macro avg       0.92      0.92      0.92      1128\n","          weighted avg       0.92      0.92      0.92      1128\n","\n"]}]},{"cell_type":"code","source":["# Load the breast_cancer dataset\n","d = fetch_20newsgroups()"],"metadata":{"id":"TOYoSKbdGvaf","executionInfo":{"status":"ok","timestamp":1701346915280,"user_tz":-330,"elapsed":8193,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["X, y = d.data, d.target\n","y = y.astype(int)"],"metadata":{"id":"RyfztyCvHb0o","executionInfo":{"status":"ok","timestamp":1701346949109,"user_tz":-330,"elapsed":857,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"udyZvgXJHetL","executionInfo":{"status":"ok","timestamp":1701346951758,"user_tz":-330,"elapsed":4,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Linear SVM\n","linear_svm = SVC(kernel='linear', C=1.0)\n","linear_svm.fit(X_train[:1000], y_train[:1000])\n","linear_svm_predictions = linear_svm.predict(X_test)\n","linear_svm_accuracy = accuracy_score(y_test, linear_svm_predictions)\n","print(\"Linear SVM Accuracy:\", linear_svm_accuracy)\n","\n","# Polynomial SVM\n","poly_svm = SVC(kernel='poly', degree=3, C=1.0)\n","poly_svm.fit(X_train[:1000], y_train[:1000])\n","poly_svm_predictions = poly_svm.predict(X_test)\n","poly_svm_accuracy = accuracy_score(y_test, poly_svm_predictions)\n","print(\"Polynomial SVM Accuracy:\", poly_svm_accuracy)\n","\n","# Radial Basis Function (RBF) SVM\n","rbf_svm = SVC(kernel='rbf', C=1.0)\n","rbf_svm.fit(X_train[:1000], y_train[:1000])\n","rbf_svm_predictions = rbf_svm.predict(X_test)\n","rbf_svm_accuracy = accuracy_score(y_test, rbf_svm_predictions)\n","print(\"RBF SVM Accuracy:\", rbf_svm_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM5-Kci8Nb6r","executionInfo":{"status":"ok","timestamp":1701347455451,"user_tz":-330,"elapsed":6835,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}},"outputId":"864b8d8d-32fc-431c-cd34-26081d2ee4c1"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear SVM Accuracy: 0.9131205673758865\n","Polynomial SVM Accuracy: 0.8457446808510638\n","RBF SVM Accuracy: 0.8971631205673759\n"]}]},{"cell_type":"code","source":["# Bernoulli Naive Bayes\n","bnb = BernoulliNB()\n","bnb.fit(X_train, y_train)\n","bnb_predictions = bnb.predict(X_test)\n","bnb_accuracy = accuracy_score(y_test, bnb_predictions)\n","print(\"Bernoulli Naive Bayes Accuracy:\", bnb_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7VxI7YSNqC9","executionInfo":{"status":"ok","timestamp":1701347561469,"user_tz":-330,"elapsed":504,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}},"outputId":"f55bcb63-435e-4ea5-c282-01fe112fd25a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Bernoulli Naive Bayes Accuracy: 0.8049645390070922\n"]}]},{"cell_type":"code","source":["#KNN\n","from sklearn.neighbors import KNeighborsClassifier\n","knnClassifier= KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2 )\n","knnClassifier.fit(X_train, y_train)\n","y_predKnn= knnClassifier.predict(X_test)\n","knn_accuracy = accuracy_score(y_test, y_predKnn)\n","print(\"KNeighborsClassifier Accuracy:\", knn_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qg4W6y1gHz59","executionInfo":{"status":"ok","timestamp":1701346007558,"user_tz":-330,"elapsed":10,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}},"outputId":"e1838db6-33ac-4e16-f095-ced9cb4bcf7a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["KNeighborsClassifier Accuracy: 0.011235955056179775\n"]}]},{"cell_type":"code","source":["#Decision Tree\n","from sklearn.tree import DecisionTreeClassifier\n","DecClassifier= DecisionTreeClassifier(criterion='entropy', random_state=0)\n","DecClassifier.fit(X_train, y_train)\n","y_predDec= DecClassifier.predict(X_test)\n","dec_accuracy = accuracy_score(y_test, y_predDec)\n","print(\"DecisionTreeClassifier Accuracy:\", dec_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbcon-JCIFWr","executionInfo":{"status":"ok","timestamp":1701346072727,"user_tz":-330,"elapsed":1104,"user":{"displayName":"Om Jadhav","userId":"08907511277767535156"}},"outputId":"9b3f9a5e-c9c6-4c7f-b68d-0964803a7f57"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["DecisionTreeClassifier Accuracy: 0.011235955056179775\n"]}]}]}